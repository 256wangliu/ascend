---
title: "ASCEND Tutorial"
author: "Anne Senabouth"
date: "14/07/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::load_all(pkg = "/Users/a.senabouth/Code Repositories/ASCEND")
library(BiocParallel)
library(Matrix)
library(gridExtra)
```

## Setting up R
#### Configuring BiocParallel
This package makes extensive use of [BiocParallel](http://bioconductor.org/packages/release/bioc/html/BiocParallel.html) for its functions. Before you begin, you should register a BiocParallel backend in order to get the best performance out of this package.

##### Single-machine multicore (Linux/Unix)
```{r, eval = FALSE}
ncores <- parallel::detectCores() - 1
register(MulticoreParam(workers = ncores, progressbar=TRUE), default = TRUE)
```

#### Single-machine multicore (Windows, SNOW)
```{r, eval = FALSE}
workers <- 3
register(SnowParam(workers = workers, type = "SOCK", progressbar = TRUE), default = TRUE)
```

#### Cluster (PBSPro)
```{r}
#example cluster code
```

## Loading Data for use in ASCEND
### Preparing data manually
We will use the "t_3k_4k_aggregate" dataset generated by 10x Genomics for this tutorial. This dataset is comprised of two batches of pan T cells from a healthy donor, and was generated with the Chromium system.

You can download the dataset from [here](http://cf.10xgenomics.com/samples/cell-exp/1.3.0/t_3k_4k_aggregate/t_3k_4k_aggregate_filtered_gene_bc_matrices_mex.tar.gz).

This download contains the following files:
- barcodes.tsv
- genes.tsv
- matrix.mtx

These files contain all the information we need to create the *AEMSet* object, the main object we will use for our workflow.

*barcodes.tsv* is a sparse matrix stored in Market Exchange Format (MEX). To read this file, we need to use the **readMM** function from the **Matrix** package and convert the sparse matrix to a data frame.
```{r}
matrix.mtx <- "/Users/a.senabouth/Data/t_3k_and_t_4k/outs/filtered_gene_bc_matrices_mex/GRCh38/matrix.mtx"
sparse.expression.matrix <- readMM(matrix.mtx)
expression.matrix <- as.matrix(sparse.expression.matrix)
expression.matrix[1:10,1:10]
```
As you can see, the matrix does not have any row or column labels. Cell Ranger has stored them in the two other files - *genes.tsv* and *barcodes.tsv*. These files also contain the information we need for the two other inputs - gene annotation information and batch information.

As these files are tab-separated variables, we can read them into R as though they are CSV files

```{r}
# Filepaths
gene.tsv <- "/Users/a.senabouth/Data/t_3k_and_t_4k/outs/filtered_gene_bc_matrices_mex/GRCh38/genes.tsv"
barcodes.tsv <- "/Users/a.senabouth/Data/t_3k_and_t_4k/outs/filtered_gene_bc_matrices_mex/GRCh38/barcodes.tsv"

# Read files into objects
genes <- read.csv(gene.tsv, sep="\t", header = FALSE)
barcodes <- read.csv(barcodes.tsv, sep="\t", header = FALSE)
```

First, we will extract the batch information from the *barcodes* data frame.

```{r}
barcodes$V1[1:10]
```

As you can see, the barcodes consist of a string of bases followed by a dash and a number. The number designates which batch the barcode has come from. There are two batches in this dataset, so we will need to retrieve the batch identifiers from this object by splitting each barcode at the "-" character, which will transform the barcode into a sub-array. We can then extract the batch identifier from the second position in the sub-array.

```{r}
batch.information <- lapply(strsplit(as.character(barcodes$V1), "-"), `[`, 2)
names(batch.information) <- barcodes$V1
batch.information[1:5]
```

The *barcodes* data frame also contains the cell identifiers. Fortunately, Cell Ranger preserves the order of the identifiers so we can add them directly to the expression matrix.

```{r}
colnames(expression.matrix) <- barcodes$V1
expression.matrix[1:5, 1:5]
```

The expression matrix is still missing its row labels, which we can retrieve from the *genes* data frame.

```{r}
genes[1:5,]
```

As you can see, there are two sets of identifiers in this document. The column labelled *V1* contains ENSEMBL transcript IDs, while *V2* contains gene names.

We will use gene names for this tutorial, as using names are more intuitive and allows us to identify controls with ease. Genes can have more than one transcript associated with them, so we also need to make the names unique before adding them to the expression matrix.

```{r}
gene.names <- make.unique(as.vector(genes$V2))
rownames(expression.matrix) <- gene.names
expression.matrix[1:5, 1:5]
```

We can change our minds however. We just need to add the *genes* data frame to our *AEMSet*, after a little more tweaking. As we have changed the gene names, we need to update the *genes* data frame with the new names.
```{r}
gene.info <- genes
gene.info$V2 <- gene.names
colnames(gene.info) <- c("ensembl_id", "gene_name")
gene.info[1:5,]

```

We are almost done with preparing the data required for an AEMSet; the last thing we need to do is to identify our controls. Usually, ribosomal and mitochondrial genes are used as controls for single-cell experiments. If used, spike-ins are also included as controls.

This particular dataset is from *Homo sapiens* and was run with spike-ins. In this reference, mitochondrial genes begin with "Mt-", ribosomal genes begin with either "Rps" or "Rpl" and spike-ins begin with "ERCC". We can therefore use the grep R function to identify these genes. We then need to organise them into a named list.

```{r}
mito.genes <- gene.info$gene_name[grep("^mt-", ignore.case=TRUE, gene.info$gene_name)]
ribo.genes <- gene.info$gene_name[grep("^rps|^rpl", ignore.case=TRUE, gene.info$gene_name)]
spike.ins <- gene.info$gene_name[grep("^ercc", ignore.case=TRUE, gene.info$gene_name)]

control.list <- list(
  Mt = mito.genes,
  Rb = ribo.genes,
  SpikeIns = spike.ins
)

control.list
```

We now have all the information! Time to load this data into an **AEMSet**.

```{r}
ascend.obj <- NewAEMSet(ExpressionMatrix = expression.matrix, GeneAnnotation = gene.info, BatchInformation = batch.information, Controls = control.list)
ascend.obj
```

### Loading Chromium data via ASCEND's CellRangerToASCEND
If you have data generated by Chromium's data processing pipeline "Cell Ranger", you can also load it directly into R using the following function:

```{r}
ascend.obj <- CellRangerToASCEND("/Users/a.senabouth/Data/t_3k_and_t_4k", "GRCh38")
ascend.obj
```

Please note that your data needs to abide by Cell Ranger's output directory structure (eg. outs/filtered_gene_bc_mex/GRCh38...)

We also need to add spike-ins to this object's controls, as the CellRangerToASCEND function assumes we only want to use mitochondrial and ribosomal genes as controls. We will retrieve the gene annotation dataframe and retrieve the spike-in information from there.

```{r}
# Retrieve gene annotation
gene.annotations <- GetGeneAnnotation(ascend.obj)
spike.ins <- gene.annotations$gene_name[grep("^ercc", ignore.case=TRUE, gene.annotations$gene_name)]

# Retrieve old control list
control.list <- GetControls(ascend.obj)

# Add spike-ins to controls
control.list <- c(control.list, list(SpikeIns = spike.ins))

# Add controls to AEMSet
ascend.obj <- UpdateControls(ascend.obj, control.list)

```
We have now added spike-ins to the control slot!

```{r}
# Examine new control list
updated.controls <- GetControls(ascend.obj)
updated.controls

```

## Single-cell post-processing and normalisation workflow
[reference https://www.bioconductor.org/help/workflows/simpleSingleCell/#overview]
### Preliminary QC
Now that we have our data loaded, we can assess its quality through a series of plots generated by *PlotGeneralQC*.
```{r, echo=FALSE}
raw.qc.plots <- PlotGeneralQC(ascend.obj)
```

*** Insert notes on what plots describe ***

### Cell filtering
#### Filtering cells by library size and genes expressed.
First, we want to remove cells with library sizes that are too small or too large, in addition to those that express too many or too few genes. We can observe the distribution of library sizes on the LibSize plot, and distribution of gene expression on the FeatureCountsPerCell plot.

```{r}
grid.arrange(raw.qc.plots$LibSize, raw.qc.plots$FeatureCountsPerCell, ncol=2)
```

This filtering step is based on Lun et al's (2017) workflow where cells are filtered out based on those with libraries and/or expression levels that are 3 median absolute deviations (MADs) below the median. You may adjust these levels accordingly.

```{r}
filtered.object <- FilterByOutliers(ascend.obj)
```

#### Filtering by controls
As we can see from the TopGeneExpression plot, mitochondrial and ribosomal genes dominate the gene expression levels. 
```{r}
raw.qc.plots$TopGenes
```

Cells that are highly expressing genes from these categories may be undergoing apoptosis, which is why we need to remove them.

```{r}
# Filter by mitochondrial genes
filtered.object <- FilterByCustomControl("Mt", 20, filtered.object)

# Filter by ribosomal genes
filtered.object <- FilterByCustomControl("Rb", 50, filtered.object )
```

#### Filtering by expression
We also need to remove low-abundance genes, which can be seen on the Log10AverageGeneCount plot.

```{r}
raw.qc.plots$Log10AverageGeneCount
```

The FilterByExpressedGenesPerCell function removes cells that have non-zero counts in at least a certain percentage of cells. In this case, we have chosen to remove cells that have non-zero counts in at least 1% of cells.

```{r}
filtered.object <- FilterByExpressedGenesPerCell(filtered.object, 0.01)
```

#### Checking our filtering
We can see how many cells have been removed by our filtering steps by referring to the log kept in the AEMSet.

```{r}
filtered.object
```
As you can see, we have removed around 3000 cells and 10 transcripts (the spike-ins). This object also maintains a list of barcodes that were removed.

We can also use the PlotGeneralQC function to generate a new set of plots, so we can see how our filtering has affected the dataset.
```{r}
filtered.qc.plots <- PlotGeneralQC(filtered.object)
filtered.qc.plots
```

As you can see, mitochondrial and ribosmal genes still dominate the top 50 expressed genes. We can exclude these genes, and also choose to only see the top 10 most-expressed genes by calling the plotting function as follows:

```{r}
top.50.expression <- PlotTopGeneExpression(filtered.object, n = 10, controls = FALSE)
top.50.expression
```

### Normalisation
The ASCEND package contains the following normalisation functions:
* NormaliseBatches
* NormaliseByRLE
* scranNormalise

How you use these functions depends on the dataset. For our example, Cell Ranger's aggr function has already normalised between batches, so we do not need to normalise library sizes between batches.

However, we do need to normalise between cells so we can either use *NormaliseByRLE* or *scranNormalise*.

#### NormaliseByRLE
This method is relatively fast as it simply normalises library sizes to relative log expression. In order to do this, it makes two assumptions: all genes have a pseudo-expression value of at least 1, and most genes are not differentially expressed. As spike-ins affect library size, they need to be removed prior to normalisation.

```{r}
# Remove spike-ins
filtered.object <- ExcludeControl(filtered.object,"SpikeIns")
rle.obj <- NormaliseByRLE(filtered.object)
```

We can see how this has affected our dataset by using a series of plots generated by PlotNormalisationQC. This function will plot the expression levels of all genes, in addition to plots specific to GAPDH and another gene, either chosen at random or specified by the user.

```{r}
rle.qc <- PlotNormalisationQC(original = filtered.object, normalised = rle.obj, gene = "ACTB")
rle.qc
```

#### scranNormalise
This function is a wrapper for the deconvolution method by Lun et al. 2015 that uses the *scran* and *scater* packages. This method takes into account the high proportion of zero counts in single-cell data, and also makes the assumption that most genes are not differentially expressed between cells. 

If your dataset consists of over 10,000 cells, this function will run scran's quickCluster in conjunction with computeSumFactors. Otherwise, it will run computeSumFactors with preset sizes of 40, 60, 80 and 100.

Please note that this function is slower and computationally intensive, and also requires controls to be defined as follows:
* Mt: Mitochondrial genes
* Rb: Ribosomal genes

This will enable ASCEND to convert the AEMSet into a SCESet, that is required for use with scran and scater.

```{r}
scran.obj <- scranNormalise(filtered.object)
```

We can also use PlotNormalisationQC to check how the normalisation process has changed our dataset.

```{r}
scran.qc <- PlotNormalisationQC(original = filtered.object, normalised = scran.obj, gene = "ACTB")
scran.qc
```

### Dimension Reduction
#### Dimension reduction via Princpal Component Analysis (PCA)
Principal component analysis (PCA) .........

```{r}
pca.obj <- RunPCA(rle.obj)
```

We can plot the results using PlotPCAVariance and see how much the top principal components contribute to the dataset.
```{r}
PlotPCAVariance(pca.obj, 50)
```

As we can see, the majority of the variances occur in the top five principal components. We can therefore safely reduce the number of principal components to 10, giving us a smaller dataset to work with.

```{r}
reduced.pca <- ReduceDimensions(pca.obj, n = 20)
```

***PCA plots?***

#### Dimension reduction via t-Distributed Stochastic Neighbour Embedding (TSNE)
We can visualise the distances between cells using tSNE. Usually, this method is computationally intensive but as we have reduced our dataset via PCA, we can simply run Rtsne's TSNE function on the reduced matrix. This reduces all the information into the number of dimensions of your own choosing.

```{r}
tsne.obj <- RunTSNE(reduced.pca, PCA = TRUE, dimensions = 2)
tsne.obj[1:10,]
```

*** PlotTSNE function ***

### Clustering
We can perform unsupervised clustering with the FindOptimalClusters function. This function performs a series of dynamicTreeCut and determines which cut height produces the most stable number of clusters. 
```{r}
clustered.obj <- FindOptimalClusters(reduced.pca)
```

We can track the stability of clusters across each height with PlotStability.
```{r}
PlotStability(clustered.obj)
```

We can also plot the resulting dendrogram with PlotDendrogram.
```{r}
PlotDendrogram(clustered.obj)
```

This dendrogram shows each cluster and their members.

### Differential Expression
*WARNING! This step is computationally intensive!*
This workflow uses DESeq to determine which genes are differentially expressed. 

#### Running differential expression with ASCEND (Slower)
This method is slow and more memory intensive, but does not require much input from the user.
##### Differential expression with a defined condition
```{r, eval = FALSE}
# Prepare condition - Cluster 1 vs Others
condition.a <- "1"
condition.b <- "Others"

# Assign a condition to each cell
cluster.list <- GetClusters(clustered.obj)
condition.list <- cluster.list
condition.list[which(condition.list != condition.a)] <- condition.b

# Transform condition list into a factor
condition.list <- as.factor(unlist(condition.list))

# Run differential expression
diff.exp.obj <- RunDiffExpression(clustered.obj, condition.a = condition.a, condition.b = condition.b, condition.list = condition.list)

```

##### Differential expression comparing each cluster to others
```{r}
diff.exp.obj <- RunClusterDiffExpression(clustered.obj)
```

#### Running differential expression manually (Faster)
This method is faster, but requires significant coding by the user. It needs to be run in a new session of R as it requires a clean environment to work from. Users also need to set up a **Parallel** cluster. This tutorial uses a cluster configured for use on Linux/Unix/MacOS systems.

```{r}
# Load R parallel package
library(parallel)

# Detect number of cores and create a parallel backend
ncores <- parallel::detectCores() - 1
cl <- parallel::makeCluster(ncores)

# Prepare condition - Cluster 1 vs Others
condition.a <- "1"
condition.b <- "Others"

# Assign a condition to each cell
cluster.list <- GetClusters(clustered.obj)
condition.list <- cluster.list
condition.list[which(condition.list != condition.a)] <- condition.b

# Transform condition list into a factor
condition.list <- as.factor(unlist(condition.list))

# Extract and chunk matrix to feed into DESeq
chunked.matrix <- PrepareCountData(clustered.obj)

# Export variables to clusters
parallel::clusterExport(cl = cl, c("condition.a", "condition.b", "condition.list"))

# Run DESeq
de.seq.results <- parallel::parLapply(cl, chunked.matrix, function(x){
  library(DESeq);
  count.dataset <- DESeq::newCountDataSet(x, condition.list);
  count.dataset <- DESeq::estimateSizeFactors(count.dataset);
  dispersions <- DESeq::estimateDispersions(count.dataset, method = 'per-condition', fitType = "local");
  DESeq.results <- DESeq::nbinomTest(dispersions, condition.a, condition.b);
  return(DESeq.results);
})

stopCluster(cl)

# Recombine chunked results and sort back into original order
diff.exp.results <- ProcessDEResults(de.seq.results)
diff.exp.results[,1:10]
```
